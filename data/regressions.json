#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
BookBible Regression Suite

Changelog (additions driven by our session):
- v1.1
  - Added lesson router + out-of-scope warnings (keyword + figure-ID range checks)
  - Added fallback term-resolution (Lesson 1 TOC, then Lesson 10 Glossary) with page→lesson map
  - Enforced "Description" verbatim-from-manifest in render_figure_block
  - Added lesson menu verification (order, count = 10)
  - Added figure-range boundary tests (first/last figure per lesson)
  - Added scope-hint injection in answers and test for it
  - Added trapdoor routing tests (Lesson 7) and quantum figure sampling (Lesson 9)

Run:
  python -m pytest -q bookbible_regress.py
or:
  python bookbible_regress.py --init bookbible.init.json --manifest figures_manifest_no_spaces.json --manuscript 3DChessBook_188.md
"""

import json
import re
import sys
import argparse
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Tuple

# ---------------------------
# Core loading & utilities
# ---------------------------

@dataclass
class Lesson:
    id: int
    name: str
    chapters: List
    fig_from: int
    fig_to: Optional[int]  # "end" -> None
    est_tokens_text: int
    est_tokens_manifest: int

@dataclass
class Config:
    version: str
    manuscript_path: Path
    manifest_path: Path
    lessons: List[Lesson]
    routing_keywords: Dict[str, List[str]]
    routing_fig_ranges: bool
    warn_template: str
    actions: List[str]
    scope_hint_format: str
    fallback_enabled: bool
    fallback_steps: List[Dict]
    page_to_lesson_map: Dict[str, int]  # stored as ranges "a-b": lesson_id
    figure_id_priority: bool

def load_config(path: Path) -> Config:
    data = json.loads(path.read_text(encoding="utf-8"))
    lessons = []
    for L in data["lessons"]:
        to_val = L["figures"]["to"]
        lessons.append(
            Lesson(
                id=L["id"],
                name=L["name"],
                chapters=L["chapters"],
                fig_from=int(L["figures"]["from"]),
                fig_to=None if to_val == "end" else int(to_val),
                est_tokens_text=int(L["est_tokens_text"]),
                est_tokens_manifest=int(L["est_tokens_manifest"])
            )
        )
    routing = data["routing"]
    out_scope = routing["out_of_scope_policy"]
    fallbacks = data.get("fallbacks", {}).get("term_resolution", {})
    mapping_rules = fallbacks.get("mapping_rules", {})
    return Config(
        version=data.get("version", "1.0"),
        manuscript_path=Path(data["manuscript_path"]),
        manifest_path=Path(data["figures_manifest_path"]),
        lessons=lessons,
        routing_keywords=routing["detect_by"]["keywords"],
        routing_fig_ranges=routing["detect_by"].get("figure_id_ranges", True),
        warn_template=out_scope["warning_template"],
        actions=out_scope["actions"],
        scope_hint_format=data.get("output_controls", {}).get("scope_hint_format", "Scope: Lesson {lesson_id} — {lesson_name}"),
        fallback_enabled=data.get("fallbacks", {}).get("term_resolution", {}).get("enabled", False),
        fallback_steps=data.get("fallbacks", {}).get("term_resolution", {}).get("steps", []),
        page_to_lesson_map=mapping_rules.get("page_to_lesson_map", {}),
        figure_id_priority=mapping_rules.get("figure_id_priority", True),
    )

def load_manifest(path: Path) -> Dict[int, Dict]:
    """
    Manifest schema expectation per entry:
      { "id": <int>, "caption": "...", "description": "...", "url": "..." }
    Returns: dict keyed by id
    """
    data = json.loads(path.read_text(encoding="utf-8"))
    # Accept both {"figures":[...]} and raw list
    figures = data.get("figures", data)
    out = {}
    for obj in figures:
        fid = int(obj["id"])
        out[fid] = obj
    return out

def load_manuscript(path: Path) -> str:
    return path.read_text(encoding="utf-8", errors="ignore")

# ---------------------------
# Lesson helpers
# ---------------------------

def get_lesson_by_id(cfg: Config, lesson_id: int) -> Lesson:
    for L in cfg.lessons:
        if L.id == lesson_id:
            return L
    raise KeyError(f"Lesson id {lesson_id} not found")

def find_lesson_for_figure(cfg: Config, fig_id: int) -> Optional[Lesson]:
    for L in cfg.lessons:
        hi = 10**12 if L.fig_to is None else L.fig_to
        if L.fig_from <= fig_id <= hi:
            return L
    return None

def lesson_for_keywords(cfg: Config, text: str) -> Optional[Lesson]:
    text_low = text.lower()
    best = None
    for key, kws in cfg.routing_keywords.items():
        if not key.startswith("lesson_"):
            continue
        lesson_id = int(key.split("_")[1])
        match = any(kw.lower() in text_low for kw in kws)
        if match:
            best = get_lesson_by_id(cfg, lesson_id)
            break
    return best

def resolve_lesson_for_query(cfg: Config, current_lesson_id: int, query: str) -> Tuple[int, bool]:
    """
    Returns: (resolved_lesson_id, out_of_scope_warning_needed)
    Strategy:
      1) Keyword map
      2) Figure ID heuristic (if user references 'Figure N')
      3) Fallbacks (Lesson 1 TOC, Lesson 10 Glossary) — simulated by keywords/page map
    """
    # 1) Keyword routing
    L_kw = lesson_for_keywords(cfg, query)
    if L_kw and L_kw.id != current_lesson_id:
        return (L_kw.id, True)
    if L_kw:
        return (L_kw.id, False)

    # 2) Figure ID heuristic
    m = re.search(r"\b[Ff]igure\s+(\d+)\b", query)
    if m:
        fid = int(m.group(1))
        L_fig = find_lesson_for_figure(cfg, fid)
        if L_fig:
            return (L_fig.id, L_fig.id != current_lesson_id)

    # 3) Fallbacks: simulate by checking glossary/TOC keywords
    if cfg.fallback_enabled:
        # We bias to Lesson 1 (TOC) then Lesson 10 (Glossary) keywords
        L1 = get_lesson_by_id(cfg, 1)
        L10 = get_lesson_by_id(cfg, 10)
        # simple "term present" keyword proxy
        if any(kw in query.lower() for kw in cfg.routing_keywords.get("lesson_1", [])):
            return (1, True if current_lesson_id != 1 else False)
        if any(kw in query.lower() for kw in cfg.routing_keywords.get("lesson_10", [])):
            return (10, True if current_lesson_id != 10 else False)

    # Default: stay put
    return (current_lesson_id, False)

# ---------------------------
# Rendering
# ---------------------------

def render_figure_block(cfg: Config, manifest: Dict[int, Dict], fig_id: int) -> Dict:
    if fig_id not in manifest:
        raise KeyError(f"Figure {fig_id} not found in manifest")
    obj = manifest[fig_id]
    # Verbatim Description is enforced by passing it through unchanged
    return {
        "id": fig_id,
        "caption": obj.get("caption", ""),
        "url": obj.get("url", ""),
        "description_verbatim": obj.get("description", ""),
        "analysis": "(analysis derived from manuscript slice here)",
        "markdown": (
            f"### Figure {fig_id}. {obj.get('caption','')}\n\n"
            f"![Figure {fig_id}: {obj.get('caption','')}]({obj.get('url','')})\n"
            f"[View on GitHub]({obj.get('url','')})\n\n"
            f"**Description (verbatim):**\n{obj.get('description','')}\n\n"
            f"**Analysis:**\n(analysis derived from manuscript slice here)\n"
        )
    }

def scope_hint(cfg: Config, lesson_id: int) -> str:
    L = get_lesson_by_id(cfg, lesson_id)
    return cfg.scope_hint_format.format(lesson_id=L.id, lesson_name=L.name)

# ---------------------------
# PyTest-style tests
# ---------------------------

def _maybe_pytest():
    try:
        import pytest  # noqa: F401
        return True
    except Exception:
        return False

def collect_sample_ids_for_lessons(cfg: Config, manifest: Dict[int, Dict], per_lesson=2) -> Dict[int, List[int]]:
    out = {}
    ids = sorted(manifest.keys())
    for L in cfg.lessons:
        hi = 10**12 if L.fig_to is None else L.fig_to
        bucket = [i for i in ids if L.fig_from <= i <= hi]
        if bucket:
            # pick first & last (or as many as available up to per_lesson)
            picks = list({bucket[0], bucket[-1]})
            out[L.id] = picks[:per_lesson]
    return out

# Test functions (pytest will auto-discover if named test_*)
def test_menu_count_and_order(cfg, manifest):
    assert len(cfg.lessons) == 10, "Lesson count must be 10"
    expected = [
        "Foundations",
        "Bedrock • Rook • Bishop • Duke",
        "Queen • Knight • Stack",
        "Pawn • King",
        "En Passant • Castling",
        "Piece-to-Piece Interactions",
        "Endgames • Midgame",
        "Openings",
        "Quantum Paradigm",
        "Appendices & References",
    ]
    got = [L.name for L in cfg.lessons]
    assert got == expected, f"Lesson names/order mismatch.\nGot: {got}\nExpected: {expected}"

def test_routing_bishop_in_lesson2(cfg, manifest):
    current = 2
    q = "Explain bishop outward planes and skew planes."
    resolved, warned = resolve_lesson_for_query(cfg, current, q)
    assert resolved == 2 and warned is False

def test_routing_out_of_scope_castling_from_lesson2(cfg, manifest):
    current = 2
    q = "How does castling work and what are the edge cases?"
    resolved, warned = resolve_lesson_for_query(cfg, current, q)
    assert resolved == 5 and warned is True

def test_render_verbatim_description_samples(cfg, manifest):
    # choose up to 6 random-looking but deterministic IDs across lessons
    sample_map = collect_sample_ids_for_lessons(cfg, manifest, per_lesson=1)
    # ensure we test at least some
    assert len(sample_map) >= 5, "Not enough manifest coverage to sample"
    for lesson_id, ids in sample_map.items():
        for fid in ids:
            block = render_figure_block(cfg, manifest, fid)
            assert block["description_verbatim"] == manifest[fid].get("description", "")
            assert f"Figure {fid}. " in block["markdown"]
            assert "**Description (verbatim):**" in block["markdown"]

def test_figure_range_boundaries(cfg, manifest):
    # For several lessons, verify that first/last IDs exist and map back to that lesson
    for L in [cfg.lessons[0], cfg.lessons[1], cfg.lessons[5], cfg.lessons[7], cfg.lessons[8]]:
        # first id
        assert any(fid >= L.fig_from and (L.fig_to is None or fid <= L.fig_to)
                   for fid in manifest.keys()), f"No figures fall into lesson {L.id}"
        # sanity mapping
        first_candidate = L.fig_from
        # If manifest has gaps, find the next present
        ids_sorted = sorted(manifest.keys())
        first_present = next((x for x in ids_sorted if x >= L.fig_from and (L.fig_to is None or x <= L.fig_to)), None)
        assert first_present is not None
        L_found = find_lesson_for_figure(cfg, first_present)
        assert L_found and L_found.id == L.id

def test_scope_hint_format(cfg, manifest):
    hint = scope_hint(cfg, 7)
    assert "Lesson 7" in hint and "Endgames • Midgame" in hint

def test_trapdoor_routing(cfg, manifest):
    current = 4  # Pawn • King
    q = "Show a trapdoor chain example with a rook"
    resolved, warned = resolve_lesson_for_query(cfg, current, q)
    assert resolved == 7 and warned is True

def test_quantum_sampling(cfg, manifest):
    # pick a known quantum-range id if present
    ids = sorted(manifest.keys())
    q_ids = [i for i in ids if 232 <= i <= 260]
    if not q_ids:
        # tolerate missing quantum range in this manifest
        return
    fid = q_ids[0]
    L = find_lesson_for_figure(cfg, fid)
    assert L and L.id == 9
    block = render_figure_block(cfg, manifest, fid)
    assert str(fid) in block["markdown"]

# ---------------------------
# CLI / PyTest integration
# ---------------------------

def _build_cfg(args) -> Tuple[Config, Dict[int, Dict], str]:
    cfg = load_config(Path(args.init))
    manifest = load_manifest(Path(args.manifest))
    manuscript = load_manuscript(Path(args.manuscript))
    return cfg, manifest, manuscript

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--init", default="bookbible.init.json")
    ap.add_argument("--manifest", default="figures_manifest_no_spaces.json")
    ap.add_argument("--manuscript", default="3DChessBook_188.md")
    args = ap.parse_args()

    cfg, manifest, manuscript = _build_cfg(args)

    # If pytest is available, delegate; else run a minimal subset
    if _maybe_pytest():
        # Hand off to pytest programmatically
        import pytest
        sys.exit(pytest.main([__file__, "-q"]))
    else:
        # Minimal self-checks if pytest not installed
        print("Running minimal checks (pytest not found)...")
        assert len(cfg.lessons) == 10
        r, w = resolve_lesson_for_query(cfg, 2, "How does castling work?")
        assert r == 5 and w is True
        # Sample a figure if any
        if manifest:
            fid = sorted(manifest.keys())[0]
            b = render_figure_block(cfg, manifest, fid)
            assert b["description_verbatim"] == manifest[fid]["description"]
        print("Minimal checks passed.")

# PyTest fixtures
def pytest_addoption(parser):
    parser.addoption("--init", action="store", default="bookbible.init.json")
    parser.addoption("--manifest", action="store", default="figures_manifest_no_spaces.json")
    parser.addoption("--manuscript", action="store", default="3DChessBook_188.md")

import pytest  # noqa: E402

@pytest.fixture(scope="session")
def cfg(pytestconfig) -> Config:
    init_path = Path(pytestconfig.getoption("--init"))
    return load_config(init_path)

@pytest.fixture(scope="session")
def manifest(pytestconfig) -> Dict[int, Dict]:
    manifest_path = Path(pytestconfig.getoption("--manifest"))
    return load_manifest(manifest_path)

@pytest.fixture(scope="session")
def manuscript(pytestconfig) -> str:
    manuscript_path = Path(pytestconfig.getoption("--manuscript"))
    return load_manuscript(manuscript_path)

if __name__ == "__main__":
    main()

